{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n/home/parker/.conda/envs/donkey/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/home/parker/.conda/envs/donkey/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/home/parker/.conda/envs/donkey/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/home/parker/.conda/envs/donkey/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/home/parker/.conda/envs/donkey/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/home/parker/.conda/envs/donkey/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
    }
   ],
   "source": [
    "import time\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import notebook\n",
    "\n",
    "from keras import backend\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 224\n",
    "width = 224\n",
    "\n",
    "content_weight = 0.75\n",
    "style_weight = 1.5\n",
    "total_variation_weight = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLayers(content_image, style_image, combination_image):\n",
    "    input_tensor = backend.concatenate([content_image,\n",
    "                                style_image,\n",
    "                                combination_image], axis=0)\n",
    "    model = VGG16(input_tensor=input_tensor)\n",
    "\n",
    "    layers = dict([(layer.name, layer.output) for layer in model.layers])\n",
    "\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_loss(content, combination):\n",
    "    return backend.sum(backend.square(combination - content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    features = backend.batch_flatten(backend.permute_dimensions(x, (2, 0, 1)))\n",
    "    gram = backend.dot(features, backend.transpose(features))\n",
    "    return gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_loss(style, combination):\n",
    "    S = gram_matrix(style)\n",
    "    C = gram_matrix(combination)\n",
    "    channels = 3\n",
    "    size = height * width\n",
    "    return backend.sum(backend.square(S - C)) / (4. * (channels ** 2) * (size ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_variation_loss(x):\n",
    "    a = backend.square(x[:, :height-1, :width-1, :] - x[:, 1:, :width-1, :])\n",
    "    b = backend.square(x[:, :height-1, :width-1, :] - x[:, :height-1, 1:, :])\n",
    "    return backend.sum(backend.pow(a + b, 1.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_loss_and_grads(x, f_outputs):\n",
    "    x = x.reshape((1, height, width, 3))\n",
    "    outs = f_outputs([x])\n",
    "    loss_value = outs[0]\n",
    "    grad_values = outs[1].flatten().astype('float64')\n",
    "    return loss_value, grad_values\n",
    "\n",
    "class Evaluator(object):\n",
    "\n",
    "    def __init__(self, f_outputs):\n",
    "        self.loss_value = None\n",
    "        self.grads_values = None\n",
    "        self.f_outs = f_outputs\n",
    "\n",
    "    def loss(self, x):\n",
    "        assert self.loss_value is None\n",
    "        loss_value, grad_values = eval_loss_and_grads(x, self.f_outs)\n",
    "        self.loss_value = loss_value\n",
    "        self.grad_values = grad_values\n",
    "        return self.loss_value\n",
    "\n",
    "    def grads(self, x):\n",
    "        assert self.loss_value is not None\n",
    "        grad_values = np.copy(self.grad_values)\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "        return grad_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImagesToArray(contentImage, styleImage):\n",
    "    contentImage = contentImage.resize((height, width))\n",
    "    styleImage = styleImage.resize((height, width))\n",
    "\n",
    "    contentArray = np.asarray(contentImage, dtype=\"float32\")\n",
    "    contentArray = np.expand_dims(contentArray, axis = 0)\n",
    "\n",
    "    styleArray = np.asarray(styleImage, dtype=\"float32\")\n",
    "    styleArray = np.expand_dims(styleArray, axis=0)\n",
    "\n",
    "    contentArray[:, :, :, 0] -= 103.939\n",
    "    contentArray[:, :, :, 1] -= 116.779\n",
    "    contentArray[:, :, :, 2] -= 123.68\n",
    "    contentArray = contentArray[:, :, :, ::-1]\n",
    "\n",
    "    styleArray[:, :, :, 0] -= 103.939\n",
    "    styleArray[:, :, :, 1] -= 116.779\n",
    "    styleArray[:, :, :, 2] -= 123.68\n",
    "    styleArray = styleArray[:, :, :, ::-1]\n",
    "    return contentArray, styleArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performStyleTransfer(contentImage, styleImage):\n",
    "    content_array, style_array = loadImagesToArray(contentImage, styleImage)\n",
    "    content_image = backend.variable(content_array)\n",
    "    style_image = backend.variable(style_array)\n",
    "    combination_image = backend.placeholder((1, height, width, 3))\n",
    "\n",
    "    layers = getLayers(content_image, style_image, combination_image)\n",
    "    loss = backend.variable(0.)\n",
    "\n",
    "    layer_features = layers['block2_conv2']\n",
    "    content_image_features = layer_features[0, :, :, :]\n",
    "    combination_features = layer_features[2, :, :, :]\n",
    "\n",
    "    loss = loss + content_weight * content_loss(content_image_features,combination_features)\n",
    "\n",
    "\n",
    "    feature_layers = ['block1_conv2', 'block2_conv2',\n",
    "                  'block3_conv3', 'block4_conv3',\n",
    "                  'block5_conv3']\n",
    "    for layer_name in feature_layers:\n",
    "        layer_features = layers[layer_name]\n",
    "        style_features = layer_features[1, :, :, :]\n",
    "        combination_features = layer_features[2, :, :, :]\n",
    "        sl = style_loss(style_features, combination_features)\n",
    "        loss += (style_weight / len(feature_layers)) * sl\n",
    "\n",
    "    \n",
    "    loss = loss + total_variation_weight * total_variation_loss(combination_image)\n",
    "\n",
    "    grads = backend.gradients(loss, combination_image)\n",
    "\n",
    "    outputs = [loss]\n",
    "    outputs = outputs + grads\n",
    "    f_outputs = backend.function([combination_image], outputs)\n",
    "\n",
    "    evaluator = Evaluator(f_outputs)\n",
    "\n",
    "    x = np.random.uniform(0, 255, (1, height, width, 3)) - 128.\n",
    "\n",
    "    iterations = 10\n",
    "\n",
    "    for i in range(iterations):\n",
    "        #print('Start of iteration', i)\n",
    "        #start_time = time.time()\n",
    "        x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n",
    "                                        fprime=evaluator.grads, maxfun=20)\n",
    "        #print('Current loss value:', min_val)\n",
    "        #end_time = time.time()\n",
    "        #print('Iteration %d completed in %ds' % (i, end_time - start_time))\n",
    "\n",
    "    x = x.reshape((height, width, 3))\n",
    "    x = x[:, :, ::-1]\n",
    "    x[:, :, 0] += 103.939\n",
    "    x[:, :, 1] += 116.779\n",
    "    x[:, :, 2] += 123.68\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    backend.clear_session() \n",
    "    result = Image.fromarray(x)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "data/tub_11_20-03-29\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=12147.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "039d2b374fbb42eb86804701ce5702c7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From /home/parker/.conda/envs/donkey/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n\n"
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-8fd4f438bd2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mstyledImage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperformStyleTransfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyledImage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mstyledName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_styled.jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewDirectory\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstyledName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-6e9dfc819261>\u001b[0m in \u001b[0;36mperformStyleTransfer\u001b[0;34m(contentImage, styleImage)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m123.68\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "directories = [\"data/tub_11_20-03-29\", \"data/flipped\"]\n",
    "newDirectory = \"data/styleTransferred\"\n",
    "style = \"seattlewf.jpg\"\n",
    "\n",
    "numPhotos = 0\n",
    "numRecs = 0\n",
    "for directory in directories:\n",
    "    print(directory)\n",
    "    for filename in notebook.tqdm(os.listdir(directory)):\n",
    "        if filename.endswith(\".jpg\"): \n",
    "            im = Image.open(directory+\"/\"+filename)\n",
    "            styledImage = Image.open(style)\n",
    "            im = performStyleTransfer(im, styledImage)\n",
    "            styledName = os.path.splitext(filename)[0]+\"_styled.jpg\"\n",
    "            im.save(newDirectory+\"/\"+styledName)\n",
    "            numPhotos += 1\n",
    "        elif filename.endswith(\".json\"):\n",
    "            with open(directory+\"/\"+filename) as json_file:\n",
    "                data = json.load(json_file)\n",
    "            styledName = os.path.splitext(filename)[0]+\"_styled.json\"\n",
    "            with open(newDirectory+\"/\"+styledName, 'w') as outfile:\n",
    "                json.dump(data, outfile)\n",
    "            numRecs += 1\n",
    "\n",
    "print(numPhotos)\n",
    "print(numRecs)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitdonkeyconda5b84108278074377a4e2bd1fc4aa4852",
   "display_name": "Python 3.7.6 64-bit ('donkey': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}